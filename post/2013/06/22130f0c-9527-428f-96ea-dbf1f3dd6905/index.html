<!DOCTYPE html>
<html>
<head>
<title> Densities and Expectations | Shawn M. O&#39;Hare</title>

<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="Shawn O’Hare">
<meta name="generator" content="Hugo 0.38-DEV" />

<link rel="stylesheet" href="https://www.shawnohare.com/css/main.css">
<link rel="stylesheet" href="https://www.shawnohare.com/css/override.css">


<script type="text/javascript" src="https://www.shawnohare.com/js/mathjax.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full">
</script>


</head>

<body>
<nav id="site" class="ui">
  <ul>
    
    <li><a href="/">home</a></li>
    
    <li><a href="/post">posts</a></li>
    
    <li><a href="/page/about">about</a></li>
    
  </ul>
</nav>

<header>
<section class="title">
<h1>Densities and Expectations</h1>

</section>


</header>
<main>
  <section id="content-meta">
  
<section class="content-meta ui">
<section class="date">24 June, 2013</section>



<section class="author">By <a href="https://www.shawnohare.com">Shawn O’Hare</a></section>









</section>


  

  </section>
  <section class="content-main"><p>For the layperson, it's probably most helpful to think of the density function <span  class="math">\(f\)</span> associated to a random variable <span  class="math">\(X\)</span> as the function you integrate to compute probabilities.  Similarly, the expected value <span  class="math">\(E(X)\)</span> is thought of as the average value that <span  class="math">\(X\)</span> takes.  Often <span  class="math">\(E(X)\)</span> is defined already in terms of the density function, and it's not clear to the beginner why <span  class="math">\(\int_{\mathbb R} x f(x) \ dx\)</span> should compute the expected value of <span  class="math">\(X\)</span>.  What should be perhaps a bit more obvious is that if you integrate <span  class="math">\(X\)</span> over the entire probability space, with respect to the given probability measure, then you obtain the average value of <span  class="math">\(X\)</span>.  This is indeed how the expectation of <span  class="math">\(X\)</span> is typically defined in a more analytical setting.</p>

<p></p>

<p>Given an arbitrary measure space <span  class="math">\((\Omega, \mathcal B, P)\)</span>, a measurable space <span  class="math">\((\Omega, \mathcal B')\)</span>, and a <span  class="math">\((\mathcal B, \mathcal B')\)</span>-measurable map <span  class="math">\(X \colon \Omega \to \Omega'\)</span>, the pushforward <span  class="math">\(P_X(E):=P(X^{-1} (E))\)</span> is a measure on <span  class="math">\(\Omega'\)</span>.  It is easy to verify that if <span  class="math">\(f \colon \Omega' \to \mathbb R\)</span> is any measurable function, then <span  class="math">\(\int_{\Omega'} f \ dP_X = \int_{\Omega} (f \circ X) \ dP\)</span>.</p>

<p>Now we us restrict ourselves to the context of a probability space <span  class="math">\((\Omega, \mathcal B, P)\)</span>.  A random variable <span  class="math">\(X \colon \Omega \to \mathbb R\)</span> is <span  class="math">\((\mathcal B, \mathcal B')\)</span>-measurable, where <span  class="math">\(\mathcal B'\)</span> denotes the Borel subsets of <span  class="math">\(\mathbb R\)</span>. The expectation <span  class="math">\(E(X)\)</span> of <span  class="math">\(X\)</span> is defined to be <span  class="math">\(\int_{\Omega} X \ dP\)</span>.  In light of the proposition above, with <span  class="math">\(1_{\mathbb R} \circ X\)</span> replacing <span  class="math">\(f \circ X\)</span> (where <span  class="math">\(1_{\mathbb R}\)</span> is the identity function on <span  class="math">\(\mathbb R\)</span>), we have</p>

<p><span  class="math">\[\begin{equation*}
  E(X) =  \int_{\Omega} X \ dP=  \int_{\Omega} 1_{\mathbb R} \circ X \ dP =\int_{\mathbb R} 1_{\mathbb R} \ d P_X= \int_{\mathbb R} x \ d P_X. 
\end{equation*}\]</span></p>

<p>The pushforward measure <span  class="math">\(P_X\)</span> gives rise to, and is determined by, a function called the distribution function of <span  class="math">\(X\)</span>, defined by <span  class="math">\(F(t):=P_X( (-\infty, t]) = P(X \leq t)\)</span>.   The density function <span  class="math">\(f\)</span> of <span  class="math">\(X\)</span> is taken to be the Radon-Nikodym derivative <span  class="math">\(d P_X/ d \lambda\)</span>, where <span  class="math">\(\lambda\)</span> is the usual Lebesgue measure on <span  class="math">\(\mathbb R\)</span>.  This means that for any Borel set <span  class="math">\(B\)</span>, the density  <span  class="math">\(f\)</span> satisfies</p>

<p><span  class="math">\[\begin{equation*}
  P(X \in B) = \int_{X^{-1}(B)} \ dP = \int_B f \ d \lambda = \int_B f \ dx.  
\end{equation*}\]</span></p>

<p>One of the properties of the Radon-Nikodym derivative is that if <span  class="math">\(g \colon \mathbb R \to \mathbb R\)</span> is <span  class="math">\(P_X\)</span>-measurable, then <span  class="math">\(\int_{\mathbb R} g \ d P_X = \int_{\mathbb R} g \cdot (d P_X/d \lambda) \ d \lambda = \int_{\mathbb R} g \cdot f \ d \lambda\)</span>. The identity function on <span  class="math">\(\mathbb R\)</span> is <span  class="math">\(P_X\)</span>-measurable, so</p>

<p><span  class="math">\[\begin{equation*}
  E(X) = \int_{\mathbb R} x \ d P_x = \int_{\mathbb R} x \cdot f(x) \ dx,  
\end{equation*}\]</span></p>

<p>which recovers the usual definition of the expectation in terms of the density.</p></section>
</main>

<footer class="ui" id="site">
  <ul>
    
  </ul>

  
  <section id="copyright">© Shawn M. O’Hare.  <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Some rights reserved</a>.</section>
</footer>
</body>
</html>
